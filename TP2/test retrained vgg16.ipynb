{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test retrained vgg16.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1xLffoJ2ymX4uw8koXOXud83Gh-i9xf8z","authorship_tag":"ABX9TyMtqpJgvtbdlyMxuvVslG6t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"KiLC1RMMFNRU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631836546894,"user_tz":180,"elapsed":3475,"user":{"displayName":"Fernando Das Neves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06324247755041763216"}},"outputId":"72ec99fa-25c7-4fdd-acb8-eed5583affbf"},"source":["# Este notebook lee un modelo de keras ya entrenado, y lo testea contra el dataset de holdout the \"10 flowers\".\n","\n","# Antes de ejecutar: Activar GPUs como sigue:\n","# menu \"Entorno de Ejecucion\" -> \"Cambiar tipo de entorno de ejecucion\" -> \"Acelerador de Hardware\" = \"GPU\"\n","\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","print(\"Usandor Tensorflow version \" + tf.__version__)\n","\n","\n","if tf.test.gpu_device_name():\n","  print('Usando GPU: {}'.format(tf.test.gpu_device_name()))\n","else:\n","  print(\"Usando CPU.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Usandor Tensorflow version 2.6.0\n","Usando CPU.\n"]}]},{"cell_type":"code","metadata":{"id":"sn9HyNB-Usq6"},"source":["from keras.models import load_model\n","import h5py\n","import numpy as np\n","\n","from typing import List\n","from skimage.transform import resize\n","from keras.preprocessing import image\n","import numpy as np\n","from os.path import join\n","from typing import List, Tuple\n","\n","\n","def read_target_names(target_names_file:str) -> List[str]:\n","    \"\"\"\n","    Lee el archivo con los nombres de categoria. Asume que es un archivo de texto\n","     donde la primera linea es el nombre de la categoria 0, la 2da linea el nombre de la categoria 1, etc.\n","    :return Una lista de nombres de categorias.\n","    \"\"\"\n","    target_names = []\n","    with open(target_names_file,\"rt\") as f:\n","        for target_name in f:\n","            target_name = target_name.strip()\n","            if len(target_name)>0:\n","                target_names.append(target_name)\n","    return target_names\n","\n","def preprocesar_imagen_como_caffe(image:np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    Transforma las imagenes, aplicando las mismas transformaciones con las que fue entrenado el modelo de VGG16 que estamos usando.\n","    :param image: Una imagen representada como una matriz de (largo en pixels, alto en pixels, 3 canales)\n","    :return La imagen transformada.\n","    \"\"\"\n","    # pasar imagen de  'RGB'->'BGR', porque el modelo ya entrenado de VGG16 que estamos usando proviene de Caffe, y fue entrenado en ese orden de channels\n","    image = image[:, :, ::-1]\n","    if image.dtype != np.float32:\n","        image = image.astype(np.float32)\n","    # central valor de los pixels alrededor del valor medio de cada canal en el conj. de entrenamiento,\n","    # esto se calcula simplemente promediando todos los valores de cada canal en todas las imagenes de entrenamiento en imagenet.\n","    image[:, :, 0] -= 103.939\n","    image[:, :, 1] -= 116.779\n","    image[:, :, 2] -= 123.68\n","    return image\n","\n","def decode_predictions(preds, labels, top=1) -> List[List[Tuple[str, float]]]:\n","    \"\"\"\n","    Transforma las predicciones en nombres de categoria, y retorna las 'top' mejores.\n","    :param preds: Un arreglo de numpy con el valor predicho por la NN para cada categoria.\n","    :param labels: Los nombres de cata categoria: debe haber tantos elementos en 'labels' como en 'preds'.\n","    :return Una lista de pares (nombre de la categoria, peso retornado por la NN para esa categoria), conteniendo los 'top' mejores resultados. \n","    \"\"\"\n","    if len(preds.shape) != 2 or preds.shape[1] != len(labels):\n","        raise ValueError('Debe haber el mismo numero de categoerias que predicciones del modelo. ' + \\\n","                         'El modelo retornó {} predicciones, pero hay {} categorias'.format(\n","                             preds.shape[1], len(labels)))\n","    results = []\n","    for pred in preds:\n","        top_indices = pred.argsort()[-top:]\n","        result = [(labels[i], pred[i]) for i in top_indices]\n","        results.append(result)\n","    return results\n","\n","def get_predictions_for_image(keras_trained_model, img:np.ndarray, labels:List[str], top_n=1) -> List[Tuple[str,float]]:\n","    \"\"\"\n","    Clasifica una imagen y retorna las 'top' mejores categorias, segun el modelo entrenado.\n","    :param keras_trained_model: Un modelo de Keras ya entrenado.\n","    :param img: Un arreglo de numpy conteniendo la imagen a clasificar.\n","    :param labels: Una lista conteniendo el nombre de cada categoria que puede predecir el modelo.\n","    :param top: Cuantos de los mejores resultados de clasificación retornar.\n","    :return Una lista de pares (nombre de la categoria, peso retornado por la NN para esa categoria), conteniendo los 'top' mejores resultados.  \n","    \"\"\"\n","    # agregar una dimension a img, porque por como fue entrenado el modelo,\n","    #la entrada que espera el modelo es siempre  de 4 dimensiones: (nro_imagenes, alto, largo, 3)\n","    img = np.expand_dims(img, axis=0)\n","    return decode_predictions(keras_trained_model.predict(img), labels, top_n)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s28lpqWLFPA6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626914833359,"user_tz":180,"elapsed":17608,"user":{"displayName":"Fernando Das Neves","photoUrl":"","userId":"06324247755041763216"}},"outputId":"4f5b64ea-6e38-4b49-8f96-f6df62145edf"},"source":["\n","\n","\n","# asume que el archivo con el modelo entrenado esta almacenado en gdrive. \n","# Si el archivo no esta esta en grdive, subalo.\n","model_file = \"/content/drive/MyDrive/collab/transfer_learning/vgg16_retrained_10flowers.h5\"\n","cnn_model = load_model(model_file)\n","# los nombres de clase estan en google drive\n","target_names = read_target_names(\"/content/drive/MyDrive/collab/transfer_learning/flowers_dataset/flower_class_index.txt\")\n","\n","# leer el dataset de test con imagenes de flores junto con y sus clases (de 0 a 9) desde google drive\n","dataset = h5py.File(\"/content/drive/MyDrive/collab/transfer_learning/flowers_dataset/data/test/flowers_holdout.h5\",'r')\n","\n","# El [()] hace que se lea el dataset completo a memoria, en vez de leerlo bajo demanda\n","images = dataset['images'][()]\n","image_labels = dataset['labels'][()]\n","image_filenames = dataset['filenames'][()]\n","tp = 0\n","for i in range(0, images.shape[0]):\n","    image = preprocesar_imagen_como_caffe(images[i])\n","    clase_real = target_names[image_labels[i,0]]\n","    clase_predicha:Tuple[str,float] = get_predictions_for_image(cnn_model, image, target_names)[0]\n","    if clase_real == clase_predicha[0][0]:\n","      tp +=1\n","    print(\"'{}' clase real:'{}', clase predicha:{}\".format(image_filenames[i][0].decode('utf-8'),clase_real, clase_predicha))\n","print(\"Accuracy =\",float(tp)/images.shape[0])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["'rose_2.png' clase real:rose, clase predicha:('rose', 0.580288)\n","'iris_2.png' clase real:iris, clase predicha:('iris', 0.6438979)\n","'peony_2.png' clase real:peony, clase predicha:('phlox', 0.8958043)\n","'rose_3.png' clase real:rose, clase predicha:('rose', 0.5022005)\n","'rose.png' clase real:rose, clase predicha:('phlox', 0.31350923)\n","'viola.png' clase real:viola, clase predicha:('phlox', 0.5555828)\n","'rudbeckia laciniata.png' clase real:rudbeckia laciniata (Goldquelle), clase predicha:('calendula', 0.2879587)\n","'phlox_2.png' clase real:phlox, clase predicha:('phlox', 0.46044692)\n","'peony.png' clase real:peony, clase predicha:('peony', 0.7392784)\n","'leucanthemum maximum_2.png' clase real:leucanthemum maximum, clase predicha:('aquilegia', 0.63716966)\n","'viola_3.png' clase real:viola, clase predicha:('phlox', 0.42449504)\n","'aquilegia_2.png' clase real:aquilegia, clase predicha:('aquilegia', 0.92374074)\n","'calendula.png' clase real:calendula, clase predicha:('calendula', 0.9989108)\n","'phlox_3.png' clase real:phlox, clase predicha:('phlox', 0.7171149)\n","'iris.png' clase real:iris, clase predicha:('bellflower', 0.4282097)\n","'phlox.png' clase real:phlox, clase predicha:('phlox', 0.39637163)\n","'leucanthemum maximum.png' clase real:leucanthemum maximum, clase predicha:('peony', 0.3925541)\n","'calendula_2.png' clase real:calendula, clase predicha:('calendula', 0.60612434)\n","'viola_2.png' clase real:viola, clase predicha:('phlox', 0.28718153)\n","'calendula_3.png' clase real:calendula, clase predicha:('calendula', 0.8292924)\n","'bellflower_2.png' clase real:bellflower, clase predicha:('phlox', 0.6052631)\n","'rudbeckia laciniata_2.png' clase real:rudbeckia laciniata (Goldquelle), clase predicha:('calendula', 0.41549993)\n","'aquilegia.png' clase real:aquilegia, clase predicha:('aquilegia', 0.47797993)\n","'bellflower.png' clase real:bellflower, clase predicha:('bellflower', 0.49100062)\n","Accuracy = 0.5416666666666666\n"],"name":"stdout"}]}]}